---
description: Writing unit or coverage tests for solidity contracts. This should be requested when editing files in ./test/ directory
globs: 
alwaysApply: false
---
**Comprehensive Prompt for Generating and Running Solidity Tests with Foundry:**

"Generate comprehensive Foundry tests for the Solidity smart contract `[ContractName]`. Tests must adhere to the project's established conventions and Foundry best practices:

**I. Test Structure and Conventions:**
1.  **File Naming:** Test files should be named `[ContractName].t.sol`. For large contracts, consider logical grouping like `[ContractName].[feature].t.sol` (e.g., `MyContract.owner.t.sol`, `MyContract.deposits.t.sol`).
2.  **Test Contract Naming & Inheritance:** Test contracts should be named `[ContractName]Test` and **must inherit from `BaseTest`** (found in `test/utils/BaseTest.t.sol`). This base contract provides numerous helper functions, pre-configured elements, and useful constants.
3.  **Function Naming:**
    *   Standard positive tests: `test_Description` (e.g., `test_IncrementAsOwner`).
    *   Fuzz tests: `testFuzz_Description` (e.g., `testFuzz_DepositUpdatesBalance`).
    *   Negative tests expecting reverts: `test_Revert[If|When]_Condition` (e.g., `test_RevertWhen_CallerNotOwner`).
    *   Fork tests: `testFork_Description`.
    *   Combine as needed, alphabetically: `testForkFuzz_RevertWhen_Condition`.
4.  **Order:** Write test contracts/functions in the same order as the original functions in the contract-under-test. Group all unit tests for the same function serially.
5.  **Internal Functions:** To test `internal` functions, create a harness contract within the test file that inherits from the contract-under-test and exposes the internal function as `external` with the naming convention `exposed_[internalFunctionName]`.
6.  **Private Functions:** If `private` functions need testing, consider changing their visibility to `internal`.
7.  **Workaround Functions:** If needed, use harness contracts to expose information not available in the original contract (e.g., length of a public array) using the pattern `workaround_[function_name]`.

**II. Test Logic and Best Practices:**
1.  **`setUp()` Function:**
    *   Use the `setUp()` function for initial state configuration (deploying contracts, creating mock users, setting initial balances).
    *   **Always call `super.setUp()`** if overriding `setUp` in your test contract, as `BaseTest` likely has its own setup logic.
    *   **Never make assertions in the `setUp` function.** If `setUp` state needs verification, use a dedicated test like `test_SetUpState()`.
2.  **Fuzz Testing:**
    *   Prioritize fuzz testing for function parameters, especially those handling user input (potential "sources" in taint analysis).
    *   Use `vm.assume` to define valid preconditions for fuzzed values and prevent trivial reverts or testing invalid states.
    *   Configure fuzz runs if necessary via comments (e.g., `/// forge-config: default.fuzz.runs = 1024`).
    *   For fork fuzz tests, be mindful of RPC usage; consider using seeds or structuring tests to minimize RPC calls.
3.  **Revert Testing:**
    *   When testing functions that should revert, use `vm.expectRevert` and verify the specific custom error selector (e.g., `vm.expectRevert(ContractName.ErrorName.selector)`).
    *   For access control errors, use the `_formatAccessControlError(address user, bytes32 role)` helper from `BaseTest.t.sol`.
    *   Avoid using the `testFail_` prefix; prefer explicit revert checking with `vm.expectRevert`.
4.  **Assertions:**
    *   Validate *all* relevant state changes in positive tests.
    *   Employ standard assertions (`assertEq`, `assertTrue`, `assertFalse`, `assertGt`, etc.) and custom assertions from `BaseTest` where appropriate (e.g., `assertEq` for `uint64[]`).
5.  **Positive and Negative Tests:** Write both positive tests (for expected behavior) and negative tests (for conditions the code should not handle).
6.  **Integration and Fork Tests:** Supplement unit tests with integration tests for entire features and fork tests to verify behavior with existing deployed contracts.

**III. Leveraging `BaseTest.t.sol` Utilities:**
    *   **User Management:** Create and manage test users with `createUser(string memory name)` and fund them.
    *   **Caller Simulation:** Simulate different callers using `vm.prank(address)`, `vm.startPrank(address)`, and `vm.stopPrank()`.
    *   **Mocking:** Mock external contract calls and return values using `vm.mockCall`.
    *   **Token Manipulation:** Use `deal` for setting token balances and `airdrop` / `takeAway` for ERC20 manipulations.
    *   **Permits:** For tests involving ERC20 permits, use `_generatePermitSignature` (for EIP-2612) or `_generatePermit2Signature`.
    *   **Oracle Timestamps:** If time-sensitive oracle data is involved (Pyth, Chainlink), use `_updatePythOracleTimeStamp` or `_updateChainLinkOracleTimeStamp`.
    *   **Constants:** Utilize constants defined in `BaseTest` or `Constants.t.sol`.
    *   **Forking:** For fork-dependent behavior, use `forkNetworkAt(string memory network, uint256 blockNumber)` or `forkNetwork(string memory network)` and `selectNamedFork(string memory network)`. Define RPC endpoints in `foundry.toml` and pin to a block for deterministic tests and caching.
    *   **Deterministic Addresses:** If needed, use `_predictDeterministicAddress` for predicting contract addresses.
    *   **State Dumping:** Use `_dumpStateWithTimestamp(string memory label)` for debugging if necessary.

**IV. Documentation and Clarity:**
    *   Ensure tests are self-contained and easy to understand.
    *   Add NatSpec comments (`/// @dev ...`, `/// @notice ...`) for complex scenarios or non-obvious logic.
    *   Focus on testing critical paths, edge cases, and potential security vulnerabilities (e.g., reentrancy, unauthorized access, data validation at "sinks").

**V. Running Tests with Foundry:**
    *   Run all tests: `forge test`
    *   Run tests in a specific contract file: `forge test --match-contract [TestContractName]` (e.g., `forge test --mc FeeCollectorTest`)
    *   Run a specific test function: `forge test --match-test [testFunctionName]` (e.g., `forge test --mt testFuzz_setSponsor`)
    *   Combine matching: `forge test --mc [TestContractName] --mt [testFunctionName]`
    *   Increase verbosity for detailed output and traces:
        *   `forge test -vvv` (level 3: logs for failing tests, traces for failing tests)
        *   `forge test -vvvvv` (level 5: logs for all tests, traces for all tests)
    *   To debug a failing test and see why it reverted (including the error message if not caught by `vm.expectRevert`): `forge test -vvvv --match-test [failingTestName]`
